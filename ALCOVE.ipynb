{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'nn';\n",
    "require 'Attention';\n",
    "require 'Association';\n",
    "require 'image';\n",
    "require 'gnuplot';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "--Three Dimensions: \n",
    "-- 1=Big/0=Small; 1=Rectangle/0=Triangle; 1=Black/0=White\n",
    "-- Differentiation between exemplars and category types would be useful\n",
    "exemplar = torch.Tensor(8,3)\n",
    "exemplar[1] = torch.Tensor({1,1,1})\n",
    "exemplar[2] = torch.Tensor({0,1,1})\n",
    "exemplar[3] = torch.Tensor({1,0,1})\n",
    "exemplar[4] = torch.Tensor({1,1,0})\n",
    "exemplar[5] = torch.Tensor({0,0,1})\n",
    "exemplar[6] = torch.Tensor({1,0,0})\n",
    "exemplar[7] = torch.Tensor({0,1,0})\n",
    "exemplar[8] = torch.Tensor({0,0,0})\n",
    "\n",
    "-- define white exemplars which can hopefully be used as logical indexes\n",
    "-- See Kruschke 1992, Fig. 4 for this\n",
    "category = torch.Tensor(6, 8)\n",
    "category[1] = torch.Tensor({0, 1, 0, 0, 1, 0, 1, 1})\n",
    "category[2] = torch.Tensor({1, 0, 0, 1, 1, 0, 0, 1})\n",
    "category[3] = torch.Tensor({1, 0, 0, 0, 1, 0, 1, 1})\n",
    "category[4] = torch.Tensor({0, 0, 0, 0, 1, 1, 1, 1})\n",
    "category[5] = torch.Tensor({1, 0, 0, 0, 1, 0, 1, 1})\n",
    "category[6] = torch.Tensor({0, 1, 1, 1, 0, 0, 0, 1})\n",
    "\n",
    "alcove = nn.Sequential()\n",
    "attention = nn.Attention(3, 8, exemplar, 6.5, 1,1)\n",
    "association = nn.Association(2,8)\n",
    "\n",
    "alcove:add(attention)\n",
    "alcove:add(association)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "probabilities = torch.Tensor(50)\n",
    "target = torch.Tensor(2)\n",
    "k = 1\n",
    "-- Over 50 epochs\n",
    "for i = 1,50 do\n",
    "    -- For each training exemplar\n",
    "    for j = 1,8 do\n",
    "        -- why modulo 8?\n",
    "        a_out = alcove:forward(exemplar[(j+i)%8 + 1]) -- forward activation\n",
    "        if exemplar[(j+i)%8 +1][1] == 1  then -- I guess here the discrimination condition is in but I can see it\n",
    "            target[1] = math.max(1,a_out[1])\n",
    "            target[2] = math.min(-1,a_out[2])\n",
    "            if j == 2 then -- Why only if j == 2? The probability for the correct classification given the rule for all stimulus should be recorded\n",
    "                probabilities[k] = (math.exp(a_out[2]*2.0))/torch.sum(torch.mul(a_out,2.0):exp())\n",
    "                k = k+1\n",
    "            end    \n",
    "        else\n",
    "            target[1] = math.min(-1,a_out[1])\n",
    "            target[2] = math.max(1,a_out[2])\n",
    "            if j == 2 then\n",
    "                probabilities[k] = (math.exp(a_out[1]*2.0))/torch.sum(torch.mul(a_out,2.0):exp())\n",
    "                k = k+1\n",
    "            end\n",
    "        end\n",
    "        alcove:backward(exemplar[(j+i)%8 + 1],target-a_out)\n",
    "    end\n",
    "    attention:updateParameters(-0.0033)\n",
    "    association:updateParameters(0.03)\n",
    "    alcove:zeroGradParameters()\n",
    "end\n",
    "x = torch.linspace(1,50,50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0,5000\n",
       " 0,5362\n",
       " 0,5727\n",
       " 0,6078\n",
       " 0,6408\n",
       " 0,6717\n",
       " 0,7013\n",
       " 0,7301\n",
       " 0,7581\n",
       " 0,7850\n",
       " 0,8106\n",
       " 0,8344\n",
       " 0,8564\n",
       " 0,8764\n",
       " 0,8945\n",
       " 0,9107\n",
       " 0,9250\n",
       " 0,9374\n",
       " 0,9483\n",
       " 0,9575\n",
       " 0,9654\n",
       " 0,9720\n",
       " 0,9776\n",
       " 0,9822\n",
       " 0,9859\n",
       " 0,9890\n",
       " 0,9914\n",
       " 0,9934\n",
       " 0,9950\n",
       " 0,9962\n",
       " 0,9971\n",
       " 0,9979\n",
       " 0,9984\n",
       " 0,9988\n",
       " 0,9992\n",
       " 0,9994\n",
       " 0,9996\n",
       " 0,9997\n",
       " 0,9998\n",
       " 0,9999\n",
       " 0,9999\n",
       " 0,9999\n",
       " 1,0000\n",
       " 1,0000\n",
       " 1,0000\n",
       " 1,0000\n",
       " 1,0000\n",
       " 1,0000\n",
       " 1,0000\n",
       " 1,0000\n",
       "[torch.DoubleTensor of size 50]\n",
       "\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnuplot.plot(x, probabilities)\n",
    "print(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
